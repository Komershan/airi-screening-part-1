/home/aaderevyagin/airi_final/venv/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:168: DeprecationWarning: [33mWARN: Current gymnasium version requires that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.
  logger.deprecation(
/home/aaderevyagin/airi_final/venv/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:181: DeprecationWarning: [33mWARN: Current gymnasium version requires that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.
  logger.deprecation(
/home/aaderevyagin/airi_final/venv/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:189: UserWarning: [33mWARN: The result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `<class 'list'>`
  logger.warn(
/home/aaderevyagin/airi_final/venv/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.observation_to_int to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.observation_to_int` for environment variables or `env.get_wrapper_attr('observation_to_int')` that will search the reminding wrappers.
  logger.warn(
/home/aaderevyagin/airi_final/venv/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:232: UserWarning: [33mWARN: Expects `truncated` signal to be a boolean, actual type: <class 'NoneType'>
  logger.warn(
/home/aaderevyagin/airi_final/venv/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:127: UserWarning: [33mWARN: The obs returned by the `step()` method should be an int or np.int64, actual type: <class 'list'>
  logger.warn(f"{pre} should be an int or np.int64, actual type: {type(obs)}")
/home/aaderevyagin/airi_final/venv/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: [33mWARN: The obs returned by the `step()` method is not within the observation space.
  logger.warn(f"{pre} is not within the observation space.")
/home/aaderevyagin/airi_final/venv/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.probs to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.probs` for environment variables or `env.get_wrapper_attr('probs')` that will search the reminding wrappers.
  logger.warn(
4 1 0.40591497578686486
2 0 0.5569498009469414
4 0 0.40591497578686486
2 1 0.5569498009469414
4 1 0.40591497578686486
2 0 0.5569498009469414
4 0 0.40591497578686486
2 1 0.5569498009469414
4 0 0.40591497578686486
2 0 0.5569498009469414
8 1 0.7386599542839085
0 0 0.1919094195827694
2 1 0.5569498009469414
8 1 0.7386599542839085
0 0 0.1919094195827694
2 0 0.5569498009469414
8 1 0.7386599542839085
2 0 0.5569498009469414
8 1 0.7386599542839085
2 1 0.5569498009469414
8 1 0.7386599542839085
2 0 0.5569498009469414
8 0 0.7386599542839085
8 1 0.7386599542839085
8 1 0.7386599542839085
0 1 0.1919094195827694
8 1 0.7386599542839085
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 1 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 0 0.7386599542839085
0 1 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 1 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 0 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 0 0.7386599542839085
0 1 0.1919094195827694
8 1 0.7386599542839085
0 1 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 1 0.1919094195827694
8 0 0.7386599542839085
0 0 0.1919094195827694
1 1 0.6116652339639777
1 1 0.6116652339639777
1 0 0.6116652339639777
1 1 0.6116652339639777
1 0 0.6116652339639777
1 1 0.6116652339639777
1 0 0.6116652339639777
1 0 0.6116652339639777
1 0 0.6116652339639777
1 1 0.6116652339639777
7 1 0.9162078783220482
9 0 0.5673543768903219
4 0 0.40591497578686486
6 0 0.016459233601365808
0 0 0.1919094195827694
6 0 0.016459233601365808
0 1 0.1919094195827694
6 0 0.016459233601365808
0 1 0.1919094195827694
6 0 0.016459233601365808
0 0 0.1919094195827694
2 0 0.5569498009469414
6 0 0.016459233601365808
0 1 0.1919094195827694
2 0 0.5569498009469414
6 0 0.016459233601365808
0 0 0.1919094195827694
6 0 0.016459233601365808
0 0 0.1919094195827694
6 0 0.016459233601365808
6 0 0.016459233601365808
4 0 0.40591497578686486
6 0 0.016459233601365808
4 1 0.40591497578686486
6 0 0.016459233601365808
4 0 0.40591497578686486
6 0 0.016459233601365808
4 1 0.40591497578686486
6 0 0.016459233601365808
4 0 0.40591497578686486
6 0 0.016459233601365808
4 0 0.40591497578686486
6 0 0.016459233601365808
4 1 0.40591497578686486
6 0 0.016459233601365808
4 0 0.40591497578686486
6 0 0.016459233601365808
4 0 0.40591497578686486
6 0 0.016459233601365808
4 1 0.40591497578686486
6 0 0.016459233601365808
4 1 0.40591497578686486
6 0 0.016459233601365808
4 1 0.40591497578686486
6 0 0.016459233601365808
4 1 0.40591497578686486
6 0 0.016459233601365808
4 1 0.40591497578686486
6 0 0.016459233601365808
4 1 0.40591497578686486
6 0 0.016459233601365808
4 1 0.40591497578686486
6 0 0.016459233601365808
4 1 0.40591497578686486
6 0 0.016459233601365808
4 0 0.40591497578686486
2 1 0.5569498009469414
8 0 0.7386599542839085
2 1 0.5569498009469414
4 0 0.40591497578686486
2 1 0.5569498009469414
4 1 0.40591497578686486
2 1 0.5569498009469414
4 0 0.40591497578686486
2 0 0.5569498009469414
2 1 0.5569498009469414
4 0 0.40591497578686486
2 1 0.5569498009469414
3 1 0.5273964256634854
7 1 0.9162078783220482
7 1 0.9162078783220482
9 0 0.5673543768903219
0 1 0.1919094195827694
2 0 0.5569498009469414
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 0 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 0 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 0 0.7386599542839085
0 1 0.1919094195827694
8 0 0.7386599542839085
0 0 0.1919094195827694
8 0 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 1 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 1 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
4 0 0.40591497578686486
6 0 0.016459233601365808
2 0 0.5569498009469414
6 0 0.016459233601365808
2 0 0.5569498009469414
6 0 0.016459233601365808
2 1 0.5569498009469414
6 0 0.016459233601365808
2 1 0.5569498009469414
6 0 0.016459233601365808
2 1 0.5569498009469414
6 0 0.016459233601365808
2 1 0.5569498009469414
6 0 0.016459233601365808
2 1 0.5569498009469414
6 0 0.016459233601365808
2 1 0.5569498009469414
6 0 0.016459233601365808
2 1 0.5569498009469414
6 0 0.016459233601365808
2 0 0.5569498009469414
6 0 0.016459233601365808
2 1 0.5569498009469414
6 0 0.016459233601365808
2 1 0.5569498009469414
6 0 0.016459233601365808
2 0 0.5569498009469414
6 0 0.016459233601365808
2 1 0.5569498009469414
6 0 0.016459233601365808
2 0 0.5569498009469414
6 0 0.016459233601365808
2 1 0.5569498009469414
6 0 0.016459233601365808
2 1 0.5569498009469414
6 0 0.016459233601365808
1 1 0.6116652339639777
1 1 0.6116652339639777
1 1 0.6116652339639777
3 0 0.5273964256634854
7 1 0.9162078783220482
9 0 0.5673543768903219
0 1 0.1919094195827694
6 0 0.016459233601365808
4 1 0.40591497578686486
2 0 0.5569498009469414
6 0 0.016459233601365808
0 0 0.1919094195827694
4 1 0.40591497578686486
2 0 0.5569498009469414
6 0 0.016459233601365808
4 1 0.40591497578686486
2 1 0.5569498009469414
4 0 0.40591497578686486
2 1 0.5569498009469414
4 1 0.40591497578686486
2 1 0.5569498009469414
4 0 0.40591497578686486
2 1 0.5569498009469414
4 0 0.40591497578686486
2 1 0.5569498009469414
4 0 0.40591497578686486
2 0 0.5569498009469414
4 1 0.40591497578686486
2 0 0.5569498009469414
4 1 0.40591497578686486
2 0 0.5569498009469414
4 0 0.40591497578686486
2 0 0.5569498009469414
4 0 0.40591497578686486
2 1 0.5569498009469414
4 1 0.40591497578686486
0 0 0.1919094195827694
8 1 0.7386599542839085
2 0 0.5569498009469414
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 0 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 1 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 1 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 0 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 1 0.1919094195827694
8 1 0.7386599542839085
0 1 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 0 0.7386599542839085
0 1 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 1 0.7386599542839085
0 0 0.1919094195827694
8 0 0.7386599542839085
0 1 0.1919094195827694
8 1 0.7386599542839085
0 1 0.1919094195827694
8 1 0.7386599542839085
6 0 0.016459233601365808
4 0 0.40591497578686486
6 0 0.016459233601365808
4 1 0.40591497578686486
6 0 0.016459233601365808
4 0 0.40591497578686486
6 0 0.016459233601365808
6 0 0.016459233601365808
4 0 0.405914975786864868
0 0 0.191909419582769468
8 1 0.738659954283908568
8 1 0.738659954283908568
6 0 0.016459233601365808
4 1 0.405914975786864868
4 1 0.405914975786864868
Traceback (most recent call last):
  File "/home/aaderevyagin/airi_final/airi-screening-part-1/./scripts/compare_arena.py", line 151, in <module>
    benchmark()
  File "/home/aaderevyagin/airi_final/venv/lib/python3.10/site-packages/pyrallis/argparsing.py", line 158, in wrapper_inner
    response = fn(cfg, *args, **kwargs)
  File "/home/aaderevyagin/airi_final/airi-screening-part-1/./scripts/compare_arena.py", line 143, in benchmark
    total_reward_model = run_env(checkpoint_model, config, agent_name=f"{checkpoint}", sampled_task=sampled_task, finish=False)
  File "/home/aaderevyagin/airi_final/airi-screening-part-1/./scripts/compare_arena.py", line 58, in run_env
    action = model.get_action(environment.observation_to_int())
  File "/home/aaderevyagin/airi_final/airi-screening-part-1/algorithms/in_context_learning/AD.py", line 195, in get_action
    logits, loss = self.forward(torch.tensor([self.history[-(self.config.block_size - 2):]]))
  File "/home/aaderevyagin/airi_final/airi-screening-part-1/algorithms/in_context_learning/AD.py", line 189, in forward
    logits = nn.functional.softmax(logits, dim=1)
  File "/home/aaderevyagin/airi_final/venv/lib/python3.10/site-packages/torch/nn/functional.py", line 1885, in softmax
    ret = input.softmax(dim)
KeyboardInterrupt